{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31e08c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc4186b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of Tic Tac Toe Board\n",
    "BOARD_ROWS = 3\n",
    "BOARD_COLS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2e58bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorized function to convert to integer\n",
    "def f(x):\n",
    "    return int(x)\n",
    "f2 = np.vectorize(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c351fc",
   "metadata": {},
   "source": [
    "#### Tic Tac Toe Game State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10ca4a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class State => with state and play management for training\n",
    "class State:\n",
    "    def __init__(self, p1, p2):\n",
    "        # initial board state\n",
    "        self.board = np.zeros((BOARD_ROWS, BOARD_COLS))\n",
    "        self.p1 = p1\n",
    "        self.p2 = p2\n",
    "        self.isEnd = False\n",
    "        # String Board standings of players \n",
    "        self.boardHash = None\n",
    "        # starting with player p1\n",
    "        self.playerSymbol = 1\n",
    "    \n",
    "    # get unique hash of current board state\n",
    "    def getHash(self):\n",
    "        # converting board standing to array\n",
    "        self.board = np.array([f2(i) for i in list(self.board)])\n",
    "        # converting array board standings to string as boardHash\n",
    "        self.boardHash = str(self.board.reshape(BOARD_COLS*BOARD_ROWS))\n",
    "        return self.boardHash\n",
    "    \n",
    "    # check for the winner\n",
    "    def winner(self):\n",
    "        # checking winner for row\n",
    "        for i in range(BOARD_ROWS):\n",
    "            # checking winner for p1 for row\n",
    "            if sum(self.board[i, :]) == 3:\n",
    "                self.isEnd = True\n",
    "                return 1\n",
    "            # checking winner for p2 for row\n",
    "            if sum(self.board[i, :]) == -3:\n",
    "                self.isEnd = True\n",
    "                return -1\n",
    "        # checking winner for col\n",
    "        for i in range(BOARD_COLS):\n",
    "            # checking winner for p1 for row\n",
    "            if sum(self.board[:, i]) == 3:\n",
    "                self.isEnd = True\n",
    "                return 1\n",
    "            # checking winner for p2 for row\n",
    "            if sum(self.board[:, i]) == -3:\n",
    "                self.isEnd = True\n",
    "                return -1\n",
    "            \n",
    "        # checking winner for diagonals\n",
    "        diag_sum1 = sum([self.board[i, i] for i in range(BOARD_COLS)])\n",
    "        diag_sum2 = sum([self.board[i, BOARD_COLS-i-1] for i in range(BOARD_COLS)])\n",
    "        # checking winner for p1 for diagonals\n",
    "        if diag_sum1 == 3 or diag_sum2 == 3:\n",
    "            self.isEnd = True\n",
    "            return 1\n",
    "        # checking winner for p2 for diagonals\n",
    "        if diag_sum1 == -3 or diag_sum2 == -3:\n",
    "            self.isEnd = True\n",
    "            return -1\n",
    "        \n",
    "        # checking for tie\n",
    "        # no available positions\n",
    "        if len(self.availablePositions()) == 0:\n",
    "            self.isEnd = True\n",
    "            return 0\n",
    "        # not end\n",
    "        self.isEnd = False\n",
    "        return None\n",
    "    \n",
    "    # check for empty positions in the board\n",
    "    def availablePositions(self):\n",
    "        positions = []\n",
    "        for i in range(BOARD_ROWS):\n",
    "            for j in range(BOARD_COLS):\n",
    "                if self.board[i, j] == 0:\n",
    "                    positions.append((i, j))  # need to be tuple\n",
    "        return positions\n",
    "    \n",
    "    # updating the board state as player makes a move with playerSymbol\n",
    "    def updateState(self, position):\n",
    "        self.board[position] = self.playerSymbol\n",
    "        # switch to another player\n",
    "        self.playerSymbol = -1 if self.playerSymbol == 1 else 1\n",
    "    \n",
    "    # Giving rewards only when game ends\n",
    "    # result = 1 => win for p1\n",
    "    # result = -1 => win for p2\n",
    "    def giveReward(self):\n",
    "        # getting the game result\n",
    "        result = self.winner()        \n",
    "        # giving rewards according to result\n",
    "        if result == 1:\n",
    "            # giving rewards when p1 wins\n",
    "            self.p1.feedReward(1)\n",
    "            self.p2.feedReward(0)\n",
    "        elif result == -1:\n",
    "            # giving rewards when p2 wins\n",
    "            self.p1.feedReward(0)\n",
    "            self.p2.feedReward(1)\n",
    "        else:\n",
    "            # giving rewards when the game is a tie\n",
    "            # giving less rewards for tie\n",
    "            self.p1.feedReward(0.001)\n",
    "            self.p2.feedReward(0.001)\n",
    "    \n",
    "    # resetting the board for new game\n",
    "    def reset(self):\n",
    "        # initializing the board and other flags for new game\n",
    "        self.board = np.zeros((BOARD_ROWS, BOARD_COLS))\n",
    "        self.boardHash = None\n",
    "        self.isEnd = False\n",
    "        self.playerSymbol = 1\n",
    "    \n",
    "    # playing function for player p1 playing with human\n",
    "    # game play\n",
    "    def play(self):\n",
    "        while not self.isEnd:\n",
    "            # Player 1\n",
    "            # first move is always made by player p1\n",
    "            \n",
    "            # getting available positions in the board\n",
    "            positions = self.availablePositions()\n",
    "            # getting action for player p1\n",
    "            p1_action = self.p1.chooseAction(positions, self.board, self.playerSymbol)\n",
    "            # taking action and upating board state\n",
    "            self.updateState(p1_action)\n",
    "            self.showBoard()\n",
    "            \n",
    "            # check board status if it is tie/win\n",
    "            win = self.winner()\n",
    "            if win is not None:\n",
    "                if win == 1:\n",
    "                    # p1 wins\n",
    "                    print(self.p1.name, \"wins!\")\n",
    "                else:\n",
    "                    # game is a tie\n",
    "                    print(\"tie!\")\n",
    "                self.reset()\n",
    "                break\n",
    "\n",
    "            else:\n",
    "                # Player 2 => Human\n",
    "                \n",
    "                # getting available positions in the board\n",
    "                positions = self.availablePositions()\n",
    "                # getting action for player p1\n",
    "                p2_action = self.p2.chooseAction(positions)\n",
    "                # taking action and upating board state\n",
    "                self.updateState(p2_action)\n",
    "                self.showBoard()\n",
    "                \n",
    "                # check board status if it is tie/win\n",
    "                win = self.winner()\n",
    "                if win is not None:\n",
    "                    if win == -1:\n",
    "                        # human player wins\n",
    "                        print(self.p2.name, \"wins!\")\n",
    "                    else:\n",
    "                        # game is a tie\n",
    "                        print(\"tie!\")\n",
    "                    self.reset()\n",
    "                    break\n",
    "\n",
    "    # Displaying game board                \n",
    "    def showBoard(self):\n",
    "        # palyer symbols\n",
    "        # p1: x  p2/human: o\n",
    "        for i in range(0, BOARD_ROWS):\n",
    "            print('-------------')\n",
    "            out = '| '\n",
    "            for j in range(0, BOARD_COLS):\n",
    "                if self.board[i, j] == 1:\n",
    "                    token = 'x'\n",
    "                if self.board[i, j] == -1:\n",
    "                    token = 'o'\n",
    "                if self.board[i, j] == 0:\n",
    "                    token = ' '\n",
    "                out += token + ' | '\n",
    "            print(out)\n",
    "        print('-------------')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d690954",
   "metadata": {},
   "source": [
    "### Player for best policy -> Simple Monte Carlo Method with Bellman Equation and exploitation rate of 70% -> 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba426898",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Player:\n",
    "    def __init__(self, name, exp_rate=0.3):\n",
    "        self.name = name # name of the player\n",
    "        self.states = []  # record all positions taken\n",
    "        self.exp_rate = exp_rate # exploitation rate -> default as 0.3 => 70%\n",
    "        # define the gamma value (discount factor)\n",
    "        self.decay_gamma = 0.9\n",
    "        self.states_value = {}  # state -> value\n",
    "    \n",
    "    \n",
    "    # get unique hash of current board state\n",
    "    def getHash(self, board):\n",
    "        # converting board standing to array\n",
    "        board = np.array([f2(i) for i in list(board)])\n",
    "         # converting array board standings to string as boardHash\n",
    "        boardHash = str(board.reshape(BOARD_COLS*BOARD_ROWS))\n",
    "        return boardHash\n",
    "    \n",
    "    # Generating next action of the player\n",
    "    def chooseAction(self, positions, current_board, symbol):\n",
    "        # getting next action randomly on the basis of exploitation value\n",
    "        if np.random.uniform(0, 1) <= self.exp_rate:\n",
    "            # This part is mainly for training purpose only\n",
    "            # take random action\n",
    "            idx = np.random.choice(len(positions))\n",
    "            action = positions[idx]\n",
    "        else:\n",
    "            # This part is for game play\n",
    "            # For gameplay the exploitation value is 0 \n",
    "            # Here next action is selected according to the saved policy \n",
    "            value_max = -999\n",
    "            for p in positions:\n",
    "                next_board = current_board.copy()\n",
    "                next_board[p] = symbol\n",
    "                next_boardHash = self.getHash(next_board)\n",
    "                # getting the next action value from the saved policy of the player during training\n",
    "                value = 0 if self.states_value.get(next_boardHash) is None else self.states_value.get(next_boardHash)\n",
    "                # print(\"value\", value)\n",
    "                if value >= value_max:\n",
    "                    value_max = value\n",
    "                    action = p\n",
    "        return action\n",
    "    \n",
    "    # appending a hash state\n",
    "    def addState(self, state):\n",
    "        self.states.append(state)\n",
    "    \n",
    "    # updating state values with calculated rewards\n",
    "    def feedReward(self, reward):\n",
    "        for st in reversed(self.states):\n",
    "            if self.states_value.get(st) is None:\n",
    "                self.states_value[st] = 0\n",
    "             # Reward Calculation => Simple Monte Carlo Method with Bellman Equation\n",
    "            self.states_value[st] = (reward + self.decay_gamma*self.states_value[st])\n",
    "            reward = self.states_value[st]\n",
    "    \n",
    "    # Resetting the states\n",
    "    def reset(self):\n",
    "        self.states = []\n",
    "    \n",
    "    # Saving the players game policies\n",
    "    def savePolicy(self):\n",
    "        fw = open('policy_' + str(self.name), 'wb')\n",
    "        pickle.dump(self.states_value, fw)\n",
    "        fw.close()\n",
    "        \n",
    "    # loding the saved policy\n",
    "    def loadPolicy(self, file):\n",
    "        fr = open(file,'rb')\n",
    "        self.states_value = pickle.load(fr)\n",
    "        fr.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "428fbd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HumanPlayer:\n",
    "    def __init__(self, name):\n",
    "        self.name = name \n",
    "    \n",
    "    def chooseAction(self, positions):\n",
    "        while True:\n",
    "            row = int(input(\"Input your action row:\"))\n",
    "            col = int(input(\"Input your action col:\"))\n",
    "            action = (row, col)\n",
    "            if action in positions:\n",
    "                return action\n",
    "    \n",
    "    # append a hash state\n",
    "    def addState(self, state):\n",
    "        pass\n",
    "    \n",
    "    # at the end of game, backpropagate and update states value\n",
    "    def feedReward(self, reward):\n",
    "        pass\n",
    "            \n",
    "    def reset(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dcb285d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "| x |   |   | \n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "Input your action row:2\n",
      "Input your action col:2\n",
      "-------------\n",
      "| x |   |   | \n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "|   |   | o | \n",
      "-------------\n",
      "-------------\n",
      "| x |   |   | \n",
      "-------------\n",
      "|   |   | x | \n",
      "-------------\n",
      "|   |   | o | \n",
      "-------------\n",
      "Input your action row:2\n",
      "Input your action col:1\n",
      "-------------\n",
      "| x |   |   | \n",
      "-------------\n",
      "|   |   | x | \n",
      "-------------\n",
      "|   | o | o | \n",
      "-------------\n",
      "-------------\n",
      "| x |   |   | \n",
      "-------------\n",
      "|   |   | x | \n",
      "-------------\n",
      "| x | o | o | \n",
      "-------------\n",
      "Input your action row:1\n",
      "Input your action col:1\n",
      "-------------\n",
      "| x |   |   | \n",
      "-------------\n",
      "|   | o | x | \n",
      "-------------\n",
      "| x | o | o | \n",
      "-------------\n",
      "-------------\n",
      "| x | x |   | \n",
      "-------------\n",
      "|   | o | x | \n",
      "-------------\n",
      "| x | o | o | \n",
      "-------------\n",
      "Input your action row:0\n",
      "Input your action col:2\n",
      "-------------\n",
      "| x | x | o | \n",
      "-------------\n",
      "|   | o | x | \n",
      "-------------\n",
      "| x | o | o | \n",
      "-------------\n",
      "-------------\n",
      "| x | x | o | \n",
      "-------------\n",
      "| x | o | x | \n",
      "-------------\n",
      "| x | o | o | \n",
      "-------------\n",
      "computer wins!\n"
     ]
    }
   ],
   "source": [
    "p1 = Player(\"computer\", exp_rate=0)\n",
    "p1.loadPolicy(\"policy_final_m1\")\n",
    "\n",
    "p2 = HumanPlayer(\"human\")\n",
    "\n",
    "st = State(p1, p2)\n",
    "st.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "371a727b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "| x |   |   | \n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "Input your action row:1\n",
      "Input your action col:1\n",
      "-------------\n",
      "| x |   |   | \n",
      "-------------\n",
      "|   | o |   | \n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "-------------\n",
      "| x |   |   | \n",
      "-------------\n",
      "|   | o | x | \n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "Input your action row:2\n",
      "Input your action col:1\n",
      "-------------\n",
      "| x |   |   | \n",
      "-------------\n",
      "|   | o | x | \n",
      "-------------\n",
      "|   | o |   | \n",
      "-------------\n",
      "-------------\n",
      "| x | x |   | \n",
      "-------------\n",
      "|   | o | x | \n",
      "-------------\n",
      "|   | o |   | \n",
      "-------------\n",
      "Input your action row:0\n",
      "Input your action col:2\n",
      "-------------\n",
      "| x | x | o | \n",
      "-------------\n",
      "|   | o | x | \n",
      "-------------\n",
      "|   | o |   | \n",
      "-------------\n",
      "-------------\n",
      "| x | x | o | \n",
      "-------------\n",
      "|   | o | x | \n",
      "-------------\n",
      "| x | o |   | \n",
      "-------------\n",
      "Input your action row:1\n",
      "Input your action col:0\n",
      "-------------\n",
      "| x | x | o | \n",
      "-------------\n",
      "| o | o | x | \n",
      "-------------\n",
      "| x | o |   | \n",
      "-------------\n",
      "-------------\n",
      "| x | x | o | \n",
      "-------------\n",
      "| o | o | x | \n",
      "-------------\n",
      "| x | o | x | \n",
      "-------------\n",
      "tie!\n"
     ]
    }
   ],
   "source": [
    "st.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99883a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "| x |   |   | \n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "Input your action row:1\n",
      "Input your action col:1\n",
      "-------------\n",
      "| x |   |   | \n",
      "-------------\n",
      "|   | o |   | \n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "-------------\n",
      "| x |   |   | \n",
      "-------------\n",
      "|   | o | x | \n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "Input your action row:2\n",
      "Input your action col:0\n",
      "-------------\n",
      "| x |   |   | \n",
      "-------------\n",
      "|   | o | x | \n",
      "-------------\n",
      "| o |   |   | \n",
      "-------------\n",
      "-------------\n",
      "| x |   |   | \n",
      "-------------\n",
      "|   | o | x | \n",
      "-------------\n",
      "| o | x |   | \n",
      "-------------\n",
      "Input your action row:0\n",
      "Input your action col:2\n",
      "-------------\n",
      "| x |   | o | \n",
      "-------------\n",
      "|   | o | x | \n",
      "-------------\n",
      "| o | x |   | \n",
      "-------------\n",
      "human wins!\n"
     ]
    }
   ],
   "source": [
    "st.play()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
